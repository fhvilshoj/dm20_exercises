{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises on Random Walks, Coverage, Sequence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tabulate\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utilities')\n",
    "from load_data import load_dblp_citations, load_city_tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Absorbing Random Walks\n",
    "Implement your own version of the absorbing random walk algorithm we discussed. Apply the algorithm in the `cit-DBLP` dataset from the [citation dataset collection](http://networkrepository.com/cit.php) in the [Network Repository](http://networkrepository.com/networks.php), which we used in the previous exercise set.\n",
    "\n",
    "Add a universal absorbing node, with probability of absorption $\\alpha$.\n",
    "For each node v in the graph, compute:\n",
    "\n",
    "1. The Personalized PageRank (PPR), with _restart probability_ $\\alpha$ (same as the probability the absorbing random walk dies), of other nodes with respect to v. Note: PPR is a special case of PageRank that restarts at node $v$.\n",
    "2. The Absorption Probability of an Absorbing Random Walk with $v$ as sink. Normalize these AR values so that the elements of the AR vector add up to $1$.\n",
    "\n",
    "Compare the JS-divergence between each vector of PPR values and the corresponding vector of normalized AP values, and also for between the matrix of all PPR values and the matrix of all normalized AP values. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, pos = load_dblp_citations()\n",
    "print(\"Number of edges: \", len(edges))\n",
    "print(\"Number of nodes: \", len(pos))\n",
    "print(\"Position example: \", pos[1])\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It turns out that there is a hell of lot of nodes with out_degree 0, so we keep removing nodes until no node is a sink node.\n",
    "G_ = G.copy()\n",
    "while len([n for n, o in G_.out_degree() if o == 0]) > 0: \n",
    "    G_.remove_nodes_from([n for n, o in G_.out_degree() if o == 0])\n",
    "    print(len([n for n, o in G_.out_degree() if o == 0]), G_.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_page_rank(G, v, alpha=0.85, tol=1e-6, max_iter=100):\n",
    "    p = np.zeros(G.number_of_nodes())\n",
    "    v_idx = next( (i for i, v_ in enumerate(G) if v_ == v) )\n",
    "    # TODO YOUR CODE HERE\n",
    "    return p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absorption_probability(G, v, alpha=0.85, tol=1e-6, max_iter=100): \n",
    "    p = np.zeros(G.number_of_nodes())\n",
    "    v_idx = next( (i for i, v_ in enumerate(G) if v_ == v) )\n",
    "    # TODO YOUR CODE HERE\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_divergence(p1, p2):\n",
    "    # TODO YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Coverage\n",
    "You are in charge of managing online customer reviews for a travel agency. \n",
    "You aim to select a small number of $k$ customer reviews per hotel, so that the set of chosen reviews captures as many aspects of the hotel as possible. \n",
    "Assume that any hotel is characterized by $m$ features, to which one review may or may not refer. \n",
    "The reviews have been already processed, so that we know which features of a hotel a certain review refers to. \n",
    "Then, for each hotel $h$, given $N$ reviews, your task is to select $k$ reviews that capture the highest possible number of features. \n",
    "Show that there is a greedy algorithm that can perform this task with a constant approximation ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Sequence Segmentation\n",
    "Eurail is designing a new collaborative schedule of itineraries between Lisbon and Stockholm. \n",
    "As part of the design, they are facing the following problem: \n",
    "\n",
    "We are given a sequence of $N$ cities along the itinerary. \n",
    "We need to divide this set of cities into groups of consecutive cities, such that each group contains at least $k$ cities, and the _total sum of the distances_ between the first and the last city in a group, summing over all groups, is **minimized** (note: only the first and the last city in each group matters when calculating this sum of distances).\n",
    "\n",
    "Assume a generic distance function $dist(city_A, city_B)$ is given.\n",
    "\n",
    "Design a scheme that quickly finds the best possible division of cities in groups under this minimization objective. \n",
    "- Try to make your algorithm as efficient as possible. \n",
    "- Provide a complexity expression for it and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities, distances = load_city_tour()\n",
    "# cities is i list of city names\n",
    "# distances is a distance matris, such that distances[i, j] is the distance from cities[i] to cities[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cities(clusters):\n",
    "    \"\"\"\n",
    "        Function to plot partitioning of the cities.\n",
    "    \"\"\"\n",
    "    d = distances[0]\n",
    "    dmin = d.min() - 50\n",
    "    dmax = d.max() + 50\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(25,3))\n",
    "\n",
    "    ax.hlines(1,dmin,dmax)  # Draw a horizontal line\n",
    "    ax.set_xlim(dmin,dmax)\n",
    "    ax.set_ylim(0.5,1.5)\n",
    "\n",
    "    y = np.ones(np.shape(d))   # Make all y values the same\n",
    "    ax.plot(d,y,'|',ms = 40)  # Plot a line at each location specified in a\n",
    "\n",
    "    # uniques = np.unique()\n",
    "    cmap = plt.get_cmap('gist_rainbow')\n",
    "    uniques = np.unique(clusters)\n",
    "    if len(uniques) == 1: cdict = dict.fromkeys(uniques, [0., 0., 0.])\n",
    "    else: \n",
    "        cdict = {}\n",
    "        for i, u in enumerate(uniques):\n",
    "            cdict[u] = cmap(float(i) / (len(uniques)-1))\n",
    "    \n",
    "    for c, pos, cl in zip(cities, d, clusters):\n",
    "        color = cdict[cl]\n",
    "        ax.text(pos, 1.15, c, rotation=90, horizontalalignment='center', color=color)\n",
    "        ax.text(pos, 0.80, \"%.0f\" % pos, rotation=90, verticalalignment='center', horizontalalignment='center', color=[0., 0., 0.])\n",
    "\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Examples of how to plot clusters\n",
    "# 1: Plot all clusters with same color.\n",
    "plot_cities(np.zeros((len(cities),)))\n",
    "\n",
    "# 2: Plos cities according to their country\n",
    "countries = [\"Portugal\", \"Spain\", \"France\", \"Belgium\", \"Netherlands\", \"Germany\", \"Denmark\", \"Sweden\"]\n",
    "country_dict = {s: i for i, s in enumerate(countries)}\n",
    "# Extract country from city \"name\" and look up the cluster in the `country_dict`.\n",
    "clusters = [country_dict[re.findall('\\((\\w+)\\)', c)[0]] for c in cities]\n",
    " \n",
    "plot_cities(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_segmentation(distances, K=3):\n",
    "    # TODO YOUR CODE HERE \n",
    "    return clusters\n",
    "\n",
    "plot_cities(sequence_segmentation(cities, distances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
