{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Handin 2\n",
    "This handin is about unsupervised methods for graph algorithms.\n",
    "\n",
    "The handin is mandatory, and should be done in groups of 2-3 students. Each group\n",
    "must prepare a report in PDF format as outlined below. Please submit all your\n",
    "Python files in a zip file, and your PDF report outside the zip file, to\n",
    "Blackboard no later than **April 7th kl. 14.14**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utilities.load_data import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theoretical questions\n",
    "\n",
    "**Report section 1:**\n",
    "\n",
    "1. Consider a (two-dimensional) dataset composed of two points\n",
    "    1. Build a similarity matrix using a threshold function on Euclidean (norm-2) distance. The metric outputs 1 if the points are close enough according to a threshold and zero otherwise. Consider two cases: when the two datapoints are close or far.\n",
    "    2. Build the Laplacian in each case and discuss the eigenvalues and eigenvectors.\n",
    "2. What are the limitations of modualarity? \n",
    "3. Consider a dataset composed of four points with two pairs of points that are close to each other, one pair being far from the other. More formally, assume that the similarity matrix looks as follows:\n",
    "\n",
    "$$\n",
    "S=\\left[\\begin{array}{cccc}\n",
    "1 & 0.8 & 0 & 0\\\\\n",
    "0.8 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0.5\\\\\n",
    "0 & 0 & 0.5 & 1\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "What are the eigenvalues and eigenvectors of $L = D - S$? How many connected components do you obtain?\n",
    "\n",
    "4. What is the PageRank of a complete graph with $n$ nodes? \n",
    "5. What is the PageRank of a complete bipartite graph with 2 nodes on one side and 4 on the other side and $\\alpha=1$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spectral clustering\n",
    "\n",
    "We will now proceed with community detection algorithms. \n",
    "For this part of the hand in, we will try to cluster a subset of the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, *_ = load_mnist()\n",
    "np.random.seed(1)\n",
    "\n",
    "n, h, w = X_train.shape\n",
    "sel = np.random.permutation(n)\n",
    "X = X_train[sel]\n",
    "y = y_train[sel]\n",
    "\n",
    "fig, ax = plt.subplots(2,6, figsize=(10, 3))\n",
    "for i in range(2): \n",
    "    for j in range(6):\n",
    "        ax[i, j].imshow(X[i*4 + j])\n",
    "        ax[i, j].set_title(\"Label: %d\" % y[i*4 + j])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report section 2:**  \n",
    "1. Take the dataset and construct the $\\varepsilon$-neighborhood graph, using Eucledian (L2) distance. Try with different epsilons and plot the graphs. What do you observe as epsilon increases? You can use the code below to plot the graph if you wish.\n",
    "2. Compare the eigenvectors of the adjacency matrix, the normalized laplacian, and the random walk laplacian. Plot the eigenvectors of the different matrices. How do they relate? \n",
    "3. Run spectral clustering with the random walk and the normalized laplacian.\n",
    "4. Record the performance with NMI. Provide a suitable implementation of NMI.  \n",
    "5. There seem to be a relationship with spectral clustering and DBSCAN, what is that? Can you guess? _Hint_: Think about the $\\varepsilon$-neighborhood graph constructed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load 200 random samples from the MNIST training set.\n",
    "X_ = X[:200].reshape(-1, 784)\n",
    "X_ = (X_ - X_.mean(1, keepdims=True)) / X_.std(1, keepdims=True)\n",
    "y_ = y[:200]\n",
    "\n",
    "def plot_neighborhood_graph(G, pos, ax):\n",
    "    ax.axis('off')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    nx.draw_networkx_edges(G,pos=pos,ax=ax, alpha=0.3)\n",
    "    nx.draw_networkx_nodes(G,pos=pos,ax=ax, node_color=y_, node_size=50, cmap=plt.get_cmap('tab10'))\n",
    "    \n",
    "    ax.set_xlim(-1.1,1.1)\n",
    "    ax.set_ylim(-1.1,1.1)\n",
    "    \n",
    "def plot_img_neighborhood_graph(G, X, pos, ax):\n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    trans=ax.transData.transform\n",
    "    trans2=fig.transFigure.inverted().transform\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos=pos, ax=ax, alpha=0.3)\n",
    "    \n",
    "    ax.set_xlim(-1.1,1.1)\n",
    "    ax.set_ylim(-1.1,1.1)\n",
    "    \n",
    "    # Add images to graph\n",
    "    piesize=0.02 # this is the image size\n",
    "    p2=piesize/2.0\n",
    "    for n in G.nodes:\n",
    "        xx,yy=trans(pos[n]) # figure coordinates\n",
    "        xa,ya=trans2((xx,yy)) * np.array([1.001, 0.93]) + np.array([0., 0.04]) # axes coordinates\n",
    "        a = plt.axes([xa-p2,ya-p2, piesize, piesize])\n",
    "        # a = plt.axes([xa-p2,ya-p2, piesize, piesize])\n",
    "        a.set_aspect('equal')\n",
    "        a.imshow(X_[n].reshape(28, 28))\n",
    "        a.axis('off')\n",
    "        \n",
    "# TODO YOUR CODE HERE \n",
    "# G = ...\n",
    "# TODO END CODE\n",
    "\n",
    "# Compute positions of nodes in G for plotting\n",
    "pos=nx.spring_layout(G)\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "ax=plt.subplot(121)\n",
    "plot_neighborhood_graph(G, pos, ax)\n",
    "ax=plt.subplot(122)\n",
    "plot_img_neighborhood_graph(G, X, pos, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph embeddings\n",
    "\n",
    "In this final exercise, we will try a different approach for clustering the data from above.\n",
    "The strategy is going to be the following:\n",
    "\n",
    "1. Build a PPR similarity matrix. \n",
    "1. Use the similarity matrix with VERSE [[1]](https://arxiv.org/pdf/1803.04742.pdf) to produce embeddings of the nodes in the graph.\n",
    "2. Use K-Means to cluster the embeddings.\n",
    "\n",
    "Your task is to i) fill in the methods below to implement the sampling version of VERSE. _Hint:_ it might be a help to look in the original article.\n",
    "and ii) run K-means on the embeddings to evaluate the performance compared to Spectral clustering using the NMI as measure.\n",
    "\n",
    "**Report section 3:**  \n",
    "1. Summary of your experiments.\n",
    "2. An analysis of the running time of the VERSE code.\n",
    "3. Can you think to a way of skipping the generation of the PageRank matrix and still preserving the correct distribution? _Hint_: think to what other methods have done.\n",
    "\n",
    "[[1](https://arxiv.org/pdf/1803.04742.pdf)] Tsitsulin, A., Mottin, D., Karras, P. and MÃ¼ller, E., 2018, April. Verse: Versatile graph embeddings from similarity measures. In Proceedings of the 2018 World Wide Web Conference (pp. 539-548)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    ''' Return the sigmoid function of x \n",
    "        x: the input vector\n",
    "    '''\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    return x\n",
    "\n",
    "def pagerank_matrix(G, alpha = 0.85) :     \n",
    "    ''' Return the PPR matrix of a graph\n",
    "\n",
    "        Args:\n",
    "            G: the input graph\n",
    "            alpha: the dumping factor of  PageRank\n",
    "\n",
    "        :return The nxn PageRank matrix P\n",
    "    '''\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    return P\n",
    "    \n",
    "\n",
    "def update(u, v, Z, C, step_size) :\n",
    "    '''Update the matrix Z using row-wise gradients of the loss function\n",
    "\n",
    "       Args:\n",
    "            u : the first node\n",
    "            v : the second node\n",
    "            Z : the embedding matrix\n",
    "            C : the classification variable used in Noise Contrastive estimation indicating whether the sample is positive or negative\n",
    "            step_size: step size for gradient descent\n",
    "\n",
    "\n",
    "       :return nothing, just update rows Z[v,:] and and Z[u,:]\n",
    "    '''\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "def verse(G, S, d, k = 3, step_size = 0.0025, steps = 10000): \n",
    "    ''' Return the sampled version of VERSE\n",
    "\n",
    "        Args:\n",
    "            G: the input Graph\n",
    "            S: the PageRank similarity matrix\n",
    "            d: dimension of the embedding space\n",
    "            k: number of negative samples\n",
    "            step_size: step size for gradient descent\n",
    "            steps: number of iterations\n",
    "\n",
    "        :return the embedding matrix nxd\n",
    "    '''\n",
    "    n = G.number_of_nodes()\n",
    "    Z = 1/d*np.random.rand(n,d)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code runs the `verse` algorithm above on G and stores the embeddings to 'verse.npy'\n",
    "P   = pagerank_matrix(G)\n",
    "emb = verse(G, P, 128, step_size=0.0025, steps=10_000)\n",
    "np.save('verse.npy', emb)\n",
    "\n",
    "# TODO\n",
    "# Run K-means multiple times and choose the best.\n",
    "# Compare to Spectral clustering on G, according to NMI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "As part of the handin you must submit the following.\n",
    "\n",
    "### Code\n",
    "You must include a `.py` file including your implementations from Exercise 2 and 3. Alternatively, you could code everything in here and upload the final IPython Notebook. \n",
    "\n",
    "### Report\n",
    "Your report should be 1-3 pages and clearly state who is in the group. It must cover:\n",
    "\n",
    "* Summary/Abstract: The status of the work, i.e., does it work, if not, then why.\n",
    "* Answers to the report sections stated above.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
